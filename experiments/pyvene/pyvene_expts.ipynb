{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyvene as pv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set Activations to Zeros with Subspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drdo/anaconda3/envs/nlp/lib/python3.12/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "# built-in helper to get a HuggingFace model\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "\n",
    "# create with dict-based config\n",
    "pv_config = pv.IntervenableConfig({\n",
    "  \"layer\": 0,\n",
    "  \"component\": \"mlp_output\"},\n",
    "  intervention_types=pv.VanillaIntervention\n",
    ")\n",
    "\n",
    "#initialize model\n",
    "# mode = parallel\n",
    "pv_gpt2 = pv.IntervenableModel(pv_config, model=gpt2)\n",
    "\n",
    "# run an intervened forward pass\n",
    "intervened_outputs = pv_gpt2(\n",
    "  # the intervening base input\n",
    "  base=tokenizer(\"The capital of Spain is\", return_tensors=\"pt\"), \n",
    "  # the location to intervene at (3rd token)\n",
    "  # used as key to get desired activation at given layer\n",
    "  unit_locations={\"base\": 3}, # -> {'sources->base': (None, [[[3]]])}, 1st val sources, 2nd val base\n",
    "  # the individual dimensions targetted\n",
    "  subspaces=[10,11,12], # -> [[[10, 11, 12]]], replace at only these dims\n",
    "  # source_reps = {intervention_name -> source_rep}\n",
    "  source_representations=torch.zeros(gpt2.config.n_embd) \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interchange Interventions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drdo/anaconda3/envs/nlp/lib/python3.12/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n"
     ]
    }
   ],
   "source": [
    "# built-in helper to get a HuggingFace model\n",
    "_, tokenizer, gpt2 = pv.create_gpt2()\n",
    "# create with dict-based config\n",
    "pv_config = pv.IntervenableConfig({\n",
    "  \"layer\": 0,\n",
    "  \"component\": \"mlp_output\"},\n",
    "  intervention_types=pv.VanillaIntervention\n",
    ")\n",
    "#initialize model\n",
    "pv_gpt2 = pv.IntervenableModel(\n",
    "  pv_config, model=gpt2)\n",
    "# run an interchange intervention \n",
    "intervened_outputs = pv_gpt2(\n",
    "  # the base input\n",
    "  base=tokenizer(\n",
    "    \"The capital of Spain is\", \n",
    "    return_tensors = \"pt\"), \n",
    "  # the source input\n",
    "  sources=tokenizer(\n",
    "    \"The capital of Italy is\", \n",
    "    return_tensors = \"pt\"), \n",
    "  # the location to intervene at (3rd token)\n",
    "  unit_locations={\"sources->base\": 3},\n",
    "  # the individual dimensions targeted\n",
    "  subspaces=[10,11,12]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Factual recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyvene\n",
    "from pyvene import embed_to_distrib, top_vals, format_token\n",
    "from pyvene import RepresentationConfig, IntervenableConfig, IntervenableModel\n",
    "from pyvene import VanillaIntervention\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg']\n",
    "from plotnine import (\n",
    "    ggplot,\n",
    "    geom_tile,\n",
    "    aes,\n",
    "    facet_wrap,\n",
    "    theme,\n",
    "    element_text,\n",
    "    geom_bar,\n",
    "    geom_hline,\n",
    "    scale_y_log10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drdo/anaconda3/envs/nlp/lib/python3.12/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded model\n",
      "The capital of Spain is\n",
      "_Madrid              0.10501297563314438\n",
      "_the                 0.09497053176164627\n",
      "_Barcelona           0.07027736306190491\n",
      "_a                   0.04010061174631119\n",
      "_now                 0.028243165463209152\n",
      "_in                  0.02760007046163082\n",
      "_Spain               0.022992383688688278\n",
      "_Catalonia           0.01882333680987358\n",
      "_also                0.018688397482037544\n",
      "_not                 0.017356621101498604\n",
      "\n",
      "The capital of Italy is\n",
      "_Rome                0.1573489010334015\n",
      "_the                 0.07316398620605469\n",
      "_Milan               0.04687740281224251\n",
      "_a                   0.03449936583638191\n",
      "_now                 0.032003238797187805\n",
      "_in                  0.023065846413373947\n",
      "_also                0.022748125717043877\n",
      "_home                0.019202813506126404\n",
      "_not                 0.016405250877141953\n",
      "_Italy               0.01577123813331127\n"
     ]
    }
   ],
   "source": [
    "config, tokenizer, gpt = pyvene.create_gpt2()\n",
    "\n",
    "base = \"The capital of Spain is\"\n",
    "source = \"The capital of Italy is\"\n",
    "inputs = [tokenizer(base, return_tensors=\"pt\"), tokenizer(source, return_tensors=\"pt\")]\n",
    "print(base)\n",
    "res = gpt(**inputs[0])\n",
    "distrib = embed_to_distrib(gpt, res.last_hidden_state, logits=False)\n",
    "top_vals(tokenizer, distrib[0][-1], n=10)\n",
    "print()\n",
    "print(source)\n",
    "res = gpt(**inputs[1])\n",
    "distrib = embed_to_distrib(gpt, res.last_hidden_state, logits=False)\n",
    "top_vals(tokenizer, distrib[0][-1], n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We path patch on two modules on each layer:\n",
    "- MLP output (the MLP output will be from another example)\n",
    "\n",
    "- MHA input (the self-attention module input will be from another module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_position_config(model_type, component, layer):\n",
    "    config = IntervenableConfig(\n",
    "        model_type=model_type,\n",
    "        representations=[\n",
    "            RepresentationConfig(\n",
    "                layer,              # layer\n",
    "                component,          # component\n",
    "                \"pos\",              # intervention unit\n",
    "                1,                  # max number of unit\n",
    "            ),\n",
    "        ],\n",
    "        intervention_types=VanillaIntervention,\n",
    "    )\n",
    "    return config\n",
    "\n",
    "\n",
    "base = tokenizer(\"The capital of Spain is\", return_tensors=\"pt\")\n",
    "sources = [tokenizer(\"The capital of Italy is\", return_tensors=\"pt\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.encode(\" Madrid Rome\")\n",
    "\n",
    "data = []\n",
    "for layer_i in range(gpt.config.n_layer):\n",
    "    config = simple_position_config(type(gpt), \"mlp_output\", layer_i)\n",
    "    intervenable = IntervenableModel(config, gpt)\n",
    "    for pos_i in range(len(base.input_ids[0])):\n",
    "        # subspaces = None -> ?\n",
    "        _, counterfactual_outputs = intervenable(\n",
    "            base, sources, {\"sources->base\": pos_i}\n",
    "        )\n",
    "        distrib = embed_to_distrib(\n",
    "            gpt, counterfactual_outputs.last_hidden_state, logits=False\n",
    "        )\n",
    "        for token in tokens:\n",
    "            data.append(\n",
    "                {\n",
    "                    \"token\": format_token(tokenizer, token),\n",
    "                    \"prob\": float(distrib[0][-1][token]),\n",
    "                    \"layer\": f\"f{layer_i}\",\n",
    "                    \"pos\": pos_i,\n",
    "                    \"type\": \"mlp_output\",\n",
    "                }\n",
    "            )\n",
    "\n",
    "    config = simple_position_config(type(gpt), \"attention_input\", layer_i)\n",
    "    intervenable = IntervenableModel(config, gpt)\n",
    "    for pos_i in range(len(base.input_ids[0])):\n",
    "        _, counterfactual_outputs = intervenable(\n",
    "            base, sources, {\"sources->base\": pos_i}\n",
    "        )\n",
    "        distrib = embed_to_distrib(\n",
    "            gpt, counterfactual_outputs.last_hidden_state, logits=False\n",
    "        )\n",
    "        for token in tokens:\n",
    "            data.append(\n",
    "                {\n",
    "                    \"token\": format_token(tokenizer, token),\n",
    "                    \"prob\": float(distrib[0][-1][token]),\n",
    "                    \"layer\": f\"a{layer_i}\",\n",
    "                    \"pos\": pos_i,\n",
    "                    \"type\": \"attention_input\",\n",
    "                }\n",
    "            )\n",
    "df = pd.DataFrame(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
