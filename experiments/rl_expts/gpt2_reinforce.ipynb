{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers datasets accelerate evaluate tensorboard nnsight wandb\n",
    "#!wandb login\n",
    "#!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "from accelerate import Accelerator\n",
    "from accelerate.utils import set_seed\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, default_data_collator,\n",
    "    get_scheduler, AutoModelForCausalLM,\n",
    "    AutoConfig, GenerationConfig,\n",
    ")\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from rouge_score import rouge_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# causal model\n",
    "# longest command is 9 words : https://arxiv.org/pdf/1711.00350\n",
    "max_len = 9\n",
    "dummy_token = \"<empty>\"\n",
    "\n",
    "# command type maps\n",
    "actions = {\n",
    "    \"walk\": \"I_WALK\",\n",
    "    \"run\": \"I_RUN\",\n",
    "    \"jump\": \"I_JUMP\",\n",
    "    \"look\": \"I_LOOK\",\n",
    "    \"turn\": dummy_token,\n",
    "    dummy_token: dummy_token,\n",
    "    }\n",
    "\n",
    "turns = {\n",
    "    \"around\": \"yyyy\",\n",
    "    \"opposite\": \"yy\",\n",
    "    dummy_token: dummy_token\n",
    "}\n",
    "\n",
    "directions = {\n",
    "    \"right\": \"I_TURN_RIGHT\",\n",
    "    \"left\": \"I_TURN_LEFT\",\n",
    "    dummy_token: dummy_token\n",
    "}\n",
    "\n",
    "nums = {\n",
    "    \"twice\": \"xx\",\n",
    "    \"thrice\": \"xxx\",\n",
    "    dummy_token: dummy_token\n",
    "}\n",
    "\n",
    "conjs = [\"and\", \"after\", dummy_token]\n",
    "\n",
    "# command structure\n",
    "command_structure = {\n",
    "    0: actions,\n",
    "    1: turns,\n",
    "    2: directions,\n",
    "    3: nums,\n",
    "    4: conjs,\n",
    "    5: actions,\n",
    "    6: turns,\n",
    "    7: directions,\n",
    "    8: nums,\n",
    "}\n",
    "\n",
    "# seed\n",
    "seed = 42\n",
    "\n",
    "# model, tokenizer\n",
    "# need to load a 'half-trained' model\n",
    "#model_name_or_path = 'distilbert/distilgpt2'\n",
    "#model_name_or_path = '/root/Caricatures/models/distilgpt2_40k'\n",
    "#model_name_or_path = '/users/ujan/caricatures/models/scan/distilgpt2_40k'\n",
    "#model_name_or_path = '/home/drdo/Caricatures/models/scan_distilgpt2/checkpoint-40000'\n",
    "model_name_or_path = '/home/drdo/Caricatures/models/scan_distilgpt2/checkpoint-5000'\n",
    "special_tokens_dict = {\n",
    "    \"pad_token\": \"<pad>\",\n",
    "    \"sep_token\": \"<sep>\",\n",
    "}\n",
    "\n",
    "# dataset\n",
    "dataset = \"scan\"\n",
    "# 'simple', 'addprim_jump', 'addprim_turn_left', 'filler_num0', \n",
    "# 'filler_num1', 'filler_num2', 'filler_num3', 'length', \n",
    "# 'template_around_right', 'template_jump_around_right', \n",
    "# 'template_opposite_right', 'template_right'\n",
    "dataset_config = \"simple\"\n",
    "validation_split = 0.1\n",
    "max_source_length = 512\n",
    "max_target_length = 512\n",
    "max_gen_length = 256\n",
    "\n",
    "# training\n",
    "#output_dir = '/users/ujan/caricatures/models/scan/scan_distilgpt2_reinforce'\n",
    "output_dir = '/home/drdo/Caricatures/models/distilgpt2_reinforce'\n",
    "#output_dir = '/root/Caricatures/models/distilgpt2_reinforce'\n",
    "num_workers = os.cpu_count()  # 1, None, 32\n",
    "per_device_train_batch_size = 16 # 64\n",
    "per_device_eval_batch_size = 16  # 64\n",
    "train_steps = 100000\n",
    "warmup_steps = 0\n",
    "gradient_accumulation_steps = 1\n",
    "eval_steps = 100\n",
    "lr = 5e-8\n",
    "weight_decay = 0.0\n",
    "lr_scheduler_type = 'linear'\n",
    "mixed_precision = 'no'\n",
    "num_beams = 1\n",
    "report_to = 'wandb'\n",
    "EPSILON = 1e-20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed and Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(seed)\n",
    "\n",
    "accelerator_log_kwargs = {}\n",
    "accelerator_log_kwargs[\"log_with\"] = report_to\n",
    "accelerator_log_kwargs[\"project_dir\"] = output_dir\n",
    "accelerator = Accelerator(gradient_accumulation_steps=gradient_accumulation_steps, **accelerator_log_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_datasets = load_dataset(dataset, dataset_config, trust_remote_code=True)\n",
    "\n",
    "# split train set into train and validation\n",
    "train_val_split = raw_datasets['train'].train_test_split(test_size=validation_split, seed=seed)\n",
    "raw_datasets['train'] = train_val_split['train']\n",
    "raw_datasets['validation'] = train_val_split['test']\n",
    "\n",
    "column_names = raw_datasets[\"train\"].column_names\n",
    "input_column = column_names[0]\n",
    "output_column = column_names[1]\n",
    "\n",
    "# format dataset with dummy tokens\n",
    "special_tokens_dict[\"additional_special_tokens\"] = [dummy_token]\n",
    "\n",
    "def add_empty_token(x):\n",
    "    command_str = x[input_column]\n",
    "    command = command_str.split()\n",
    "    padded_command = []\n",
    "    index = 0\n",
    "    c = 0\n",
    "    while index < max_len:\n",
    "        expected_cs = command_structure[index]\n",
    "        if c < len(command) and command[c] in expected_cs:\n",
    "            padded_command.append(command[c])\n",
    "            c += 1\n",
    "        else:\n",
    "            padded_command.append(dummy_token)\n",
    "        index += 1\n",
    "    \n",
    "    x[input_column] = ' '.join(padded_command)\n",
    "    return x\n",
    "\n",
    "with accelerator.main_process_first():\n",
    "    raw_datasets[\"train\"] = raw_datasets[\"train\"].map(\n",
    "        add_empty_token,\n",
    "        batched=False,\n",
    "        num_proc=num_workers, \n",
    "        desc=\"Running tokenizer on dataset\",\n",
    "    )\n",
    "    raw_datasets[\"validation\"] = raw_datasets[\"validation\"].map(\n",
    "        add_empty_token,\n",
    "        batched=False,\n",
    "        num_proc=num_workers,\n",
    "        desc=\"Running tokenizer on dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "config = AutoConfig.from_pretrained(model_name_or_path, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True, trust_remote_code=True)\n",
    "tokenizer.add_special_tokens(special_tokens_dict)\n",
    "# left padding for batch generation\n",
    "tokenizer.padding_side = \"left\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name_or_path,\n",
    "            config=config,\n",
    "            trust_remote_code=True,\n",
    "        )\n",
    "\n",
    "# Resize the embeddings only when necessary to avoid index errors\n",
    "embedding_size = model.get_input_embeddings().weight.shape[0]\n",
    "if len(tokenizer) > embedding_size:\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Generation config\n",
    "generation_config = GenerationConfig.from_pretrained(model_name_or_path)\n",
    "#gen_dict = generation_config.to_dict()\n",
    "#gen_dict[\"language\"] = model_lang\n",
    "# reload with new attributes\n",
    "#generation_config = GenerationConfig.from_dict(gen_dict)\n",
    "#max_gen_length = model.config.max_length\n",
    "#num_beams = args.num_beams if args.num_beams is not None else model.config.num_beams\n",
    "generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "gen_kwargs = {\"max_new_tokens\": max_gen_length, \"num_beams\": num_beams}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocess dataset\n",
    "def preprocess_function(examples):\n",
    "    # commands, actions\n",
    "    inputs = examples[input_column]\n",
    "    targets = examples[output_column]\n",
    "\n",
    "    # tokenize as single sequence separated by special token\n",
    "    model_inputs = tokenizer(\n",
    "        [i+tokenizer.sep_token for i in inputs],\n",
    "        padding='max_length', max_length=max_source_length\n",
    "    )\n",
    "    # labels same as inputs. labels shifted right in the model forward by default\n",
    "    model_inputs['labels'] = tokenizer(\n",
    "        [t+tokenizer.eos_token for t in targets],\n",
    "        padding='max_length', max_length=max_source_length\n",
    "    )['input_ids']\n",
    "    # set label padding to -100 \n",
    "    #model_inputs['labels'] = [\n",
    "        #[(l if l != tokenizer.pad_token_id else -100) for l in label] for label in model_inputs['labels']\n",
    "    #]\n",
    "\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "with accelerator.main_process_first():\n",
    "    train_dataset = raw_datasets[\"train\"].map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        num_proc=num_workers,\n",
    "        remove_columns=column_names,\n",
    "        desc=\"Running tokenizer on dataset\",\n",
    "    )\n",
    "    eval_dataset = raw_datasets[\"validation\"].map(\n",
    "        preprocess_function,\n",
    "        batched=True,\n",
    "        num_proc=num_workers,\n",
    "        remove_columns=column_names,\n",
    "        desc=\"Running tokenizer on dataset\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data collator and loaders\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, shuffle=True, collate_fn=default_data_collator, batch_size=per_device_train_batch_size\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_dataset, collate_fn=default_data_collator, batch_size=per_device_eval_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer and Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare optimizer and schedule (linear warmup and decay)\n",
    "no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters = [\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": weight_decay,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0,\n",
    "    },\n",
    "]\n",
    "optimizer = torch.optim.AdamW(optimizer_grouped_parameters, lr=lr)\n",
    "\n",
    "# scheduler\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=lr_scheduler_type,\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=warmup_steps * accelerator.num_processes,\n",
    "    num_training_steps=train_steps * accelerator.num_processes,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare everything for accelerator\n",
    "model, optimizer, train_dataloader, eval_dataloader, lr_scheduler = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader, lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45191379bc3d4752a1b629754da66b59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.749074074074074\n"
     ]
    }
   ],
   "source": [
    "eval_bar = tqdm(range(len(eval_dataloader)), position=0)\n",
    "accuracy = 0\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for batch in eval_dataloader:\n",
    "    with torch.no_grad():\n",
    "        output_ids = accelerator.unwrap_model(model).generate(\n",
    "            **batch,\n",
    "            generation_config=generation_config,\n",
    "            **gen_kwargs\n",
    "        )\n",
    "\n",
    "    # pad_acrss_processes to get equal length for each processs\n",
    "    output_ids = accelerator.pad_across_processes(output_ids, dim=1, pad_index=tokenizer.pad_token_id)\n",
    "    label_ids = accelerator.pad_across_processes(batch[\"labels\"], dim=1, pad_index=tokenizer.pad_token_id)\n",
    "    # gather\n",
    "    output_ids = accelerator.gather(output_ids) \n",
    "    label_ids = accelerator.gather(label_ids)  \n",
    "    # decode\n",
    "    batch_output = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "    batch_input = tokenizer.batch_decode(batch['input_ids'], skip_special_tokens=True)\n",
    "    outputs = [batch_output[b].replace(batch_input[b], '') for b in range(len(batch_output))]\n",
    "    labels = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "    # compute accuracy\n",
    "    acc = [o==l for o, l in zip(outputs, labels)]\n",
    "    accuracy += sum(acc)/len(acc)\n",
    "\n",
    "    eval_bar.update(1)\n",
    "\n",
    "print(accuracy/len(eval_dataloader))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# right padding for logits\n",
    "tokenizer.padding_side = \"right\"\n",
    "ignore_index = -100\n",
    "\n",
    "\n",
    "# re-tokenize left padded sequences need for batch generation to right padded sequences\n",
    "def re_tokenize(token_ids):\n",
    "    tokens = tokenizer.batch_decode(token_ids, skip_special_tokens=False)\n",
    "    tokens = [o.replace(tokenizer.pad_token, '') for o in tokens]\n",
    "    tokens = [o.replace(tokenizer.eos_token, '') for o in tokens]\n",
    "    tokenized_tokens = tokenizer(\n",
    "        tokens,\n",
    "        padding='max_length',\n",
    "        max_length=max_source_length,\n",
    "        return_tensors='pt',\n",
    "    ).to(model.device)\n",
    "    input_ids = tokenized_tokens['input_ids']\n",
    "    attention_mask = tokenized_tokens['attention_mask']\n",
    "    return input_ids, attention_mask\n",
    "\n",
    "\n",
    "def prepare_input_for_rl_step(output_ids, gen_label_ids):\n",
    "\n",
    "    generated_ids, attention_mask = re_tokenize(output_ids)\n",
    "    gen_label_ids, _ = re_tokenize(gen_label_ids) \n",
    "    # context labels needed for ce loss for context\n",
    "    # get only context labels\n",
    "    all_tokens = tokenizer.batch_decode(generated_ids)\n",
    "    context_tokens = [t.split(tokenizer.sep_token)[0] for t in all_tokens]\n",
    "    tokenized_context = tokenizer(\n",
    "        [c+tokenizer.sep_token for c in context_tokens],\n",
    "        padding='max_length',\n",
    "        max_length=max_source_length,\n",
    "        return_tensors='pt',\n",
    "    ).to(model.device)\n",
    "    context_label_ids = tokenized_context['input_ids']\n",
    "    # set context label padding to -100 \n",
    "    context_label_ids = [\n",
    "        [\n",
    "            (l if l != tokenizer.pad_token_id else ignore_index) for l in label\n",
    "        ] for label in context_label_ids.tolist()\n",
    "    ]\n",
    "    context_label_ids = torch.tensor(context_label_ids).to(model.device)\n",
    "\n",
    "    return generated_ids, attention_mask, gen_label_ids, context_label_ids\n",
    "    \n",
    "\n",
    "# returns 1 if accurate, 0 otherwise\n",
    "# experiment with other rewards\n",
    "def binary_reward_function(output_ids, gen_label_ids):\n",
    "    # decode output\n",
    "    output_tokens = tokenizer.batch_decode(output_ids, skip_special_tokens=False)\n",
    "    output_tokens = [\n",
    "        o.replace(tokenizer.pad_token, '').split(tokenizer.sep_token)[1] for o in output_tokens\n",
    "    ]\n",
    "    # decode labels\n",
    "    label_tokens = tokenizer.batch_decode(gen_label_ids, skip_special_tokens=False)\n",
    "    label_tokens = [l.replace(tokenizer.pad_token, '') for l in label_tokens]\n",
    "    # compute reward(=accuracy)\n",
    "    reward = [o==l for o, l in zip(output_tokens, label_tokens)]\n",
    "    reward = torch.tensor(reward, dtype=torch.float32).to(model.device)\n",
    "    return reward\n",
    "\n",
    "\n",
    "def rouge1_reward_function(output_ids, gen_label_ids):\n",
    "    scorer = rouge_scorer.RougeScorer(['rouge1'])\n",
    "    # decode output\n",
    "    output_tokens = tokenizer.batch_decode(output_ids, skip_special_tokens=False)\n",
    "    output_tokens = [\n",
    "        o.replace(tokenizer.pad_token, '').split(tokenizer.sep_token)[1] for o in output_tokens\n",
    "    ]\n",
    "    # decode labels\n",
    "    label_tokens = tokenizer.batch_decode(gen_label_ids, skip_special_tokens=False)\n",
    "    label_tokens = [l.replace(tokenizer.pad_token, '') for l in label_tokens]\n",
    "    # compute reward(=rouge1_f)\n",
    "    reward = [scorer.score(o,l)['rouge1'].fmeasure for o, l in zip(output_tokens, label_tokens)]\n",
    "    reward = torch.tensor(reward, dtype=torch.float32).to(model.device)\n",
    "    return reward\n",
    "\n",
    "\n",
    "\n",
    "def logprobs_from_logits(logits, labels):\n",
    "    # https://github.com/pytorch/pytorch/issues/563#issuecomment-330103591\n",
    "    logp = torch.log(F.softmax(logits, dim=2) + EPSILON)\n",
    "    logpy = torch.gather(logp, 2, labels.unsqueeze(2)).squeeze(-1)\n",
    "    return logpy\n",
    "    \n",
    "\n",
    "def loss_function(logits, context_label_ids, gen_label_ids, attention_mask, reward):\n",
    "\n",
    "    # ce loss for context\n",
    "    # shift so that tokens < n predict n\n",
    "    shift_logits = logits[..., :-1, :].contiguous()\n",
    "    shift_context_labels = context_label_ids[..., 1:].contiguous()\n",
    "    loss_fct = CrossEntropyLoss(ignore_index=ignore_index)\n",
    "    context_loss = loss_fct(\n",
    "        shift_logits.view(-1, shift_logits.size(-1)), shift_context_labels.view(-1)\n",
    "    )\n",
    "\n",
    "    # reinforce loss\n",
    "    # logprobs -> b x seq_len\n",
    "    logprob = logprobs_from_logits(logits, gen_label_ids)\n",
    "    # zero out context positions in logits\n",
    "    logprob[context_label_ids != ignore_index] = 0\n",
    "    # zero out padding positions in logits\n",
    "    logprob[attention_mask == 0] = 0\n",
    "    # reshape reward\n",
    "    reward = reward.unsqueeze(1).repeat(1,logprob.shape[1])\n",
    "    reinforce_loss = -logprob * reward\n",
    "\n",
    "    # total loss\n",
    "    # zero out context from attention_mask\n",
    "    attention_mask[context_label_ids != ignore_index] = 0\n",
    "    reinforce_loss = torch.sum(reinforce_loss) / torch.sum(attention_mask)\n",
    "    total_loss = context_loss + reinforce_loss\n",
    "\n",
    "    return total_loss\n",
    "    \n",
    "    \n",
    "def reinforce_step(generated_ids, attention_mask, gen_label_ids, context_label_ids):\n",
    "    # calculate reward 'to go' (reinforce)\n",
    "    # reward -> batch_size\n",
    "    #reward = binary_reward_function(generated_ids, gen_label_ids)\n",
    "    reward = rouge1_reward_function(generated_ids, gen_label_ids)\n",
    "    # model forward\n",
    "    logits = model(input_ids=generated_ids, attention_mask=attention_mask).logits\n",
    "    # compute loss\n",
    "    loss = loss_function(logits, context_label_ids, gen_label_ids, attention_mask, reward)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf783b221e24f51b23a26c40cb9b985",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71fd2a8ab8b4596b6fc8f600831dfcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/105 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 100, accuracy  : 0.7455026455026454\n",
      "step : 200, accuracy  : 0.7437169312169312\n",
      "step : 300, accuracy  : 0.7460978835978835\n",
      "step : 400, accuracy  : 0.7388227513227513\n",
      "step : 500, accuracy  : 0.7316798941798941\n",
      "step : 600, accuracy  : 0.7263227513227513\n",
      "step : 700, accuracy  : 0.7209656084656084\n"
     ]
    }
   ],
   "source": [
    "global_step = 0  # tracks total steps\n",
    "\n",
    "progress_bar = tqdm(range(global_step, train_steps), disable=not accelerator.is_main_process, position=0)\n",
    "# eval bar\n",
    "eval_bar = tqdm(range(len(eval_dataloader)), position=1)\n",
    "\n",
    "while True:\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        with torch.no_grad():\n",
    "            output_ids = accelerator.unwrap_model(model).generate(\n",
    "                **batch,\n",
    "                generation_config=generation_config,\n",
    "                **gen_kwargs\n",
    "            )\n",
    "\n",
    "        # pad_acrss_processes to get equal length for each processs\n",
    "        output_ids = accelerator.pad_across_processes(output_ids, dim=1, pad_index=tokenizer.pad_token_id)\n",
    "        label_ids = accelerator.pad_across_processes(batch[\"labels\"], dim=1, pad_index=tokenizer.pad_token_id)\n",
    "\n",
    "        # gather\n",
    "        output_ids = accelerator.gather(output_ids) \n",
    "        label_ids = accelerator.gather(label_ids)  \n",
    "\n",
    "        # re-tokenize for rl step\n",
    "        # generated_ids -> context ids + generated action ids\n",
    "        # attention mask -> attention mask for generated_ids\n",
    "        # gen_label_ids -> generated action ids\n",
    "        # context_label_ids -> context ids, needed to compute ce loss for context\n",
    "        generated_ids, attention_mask, gen_label_ids, context_label_ids = prepare_input_for_rl_step(output_ids, label_ids)\n",
    "\n",
    "        # reinforce\n",
    "        loss = reinforce_step(generated_ids, attention_mask, gen_label_ids, context_label_ids)\n",
    "\n",
    "        # backprop\n",
    "        accelerator.backward(loss)\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Checks if the accelerator has performed an optimization step behind the scenes\n",
    "        if accelerator.sync_gradients:\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        if (global_step + 1) % eval_steps == 0:\n",
    "            model.eval()\n",
    "            accuracy = 0\n",
    "            \n",
    "            for batch in eval_dataloader:\n",
    "                with torch.no_grad():\n",
    "                    output_ids = accelerator.unwrap_model(model).generate(\n",
    "                        **batch,\n",
    "                        generation_config=generation_config,\n",
    "                        **gen_kwargs\n",
    "                    )\n",
    "\n",
    "                # pad_acrss_processes to get equal length for each processs\n",
    "                output_ids = accelerator.pad_across_processes(output_ids, dim=1, pad_index=tokenizer.pad_token_id)\n",
    "                label_ids = accelerator.pad_across_processes(batch[\"labels\"], dim=1, pad_index=tokenizer.pad_token_id)\n",
    "                # gather\n",
    "                output_ids = accelerator.gather(output_ids) \n",
    "                label_ids = accelerator.gather(label_ids)  \n",
    "                # decode\n",
    "                batch_output = tokenizer.batch_decode(output_ids, skip_special_tokens=True)\n",
    "                batch_input = tokenizer.batch_decode(batch['input_ids'], skip_special_tokens=True)\n",
    "                outputs = [batch_output[b].replace(batch_input[b], '') for b in range(len(batch_output))]\n",
    "                #accelerator.print(outputs)\n",
    "                labels = tokenizer.batch_decode(label_ids, skip_special_tokens=True)\n",
    "                # compute accuracy\n",
    "                acc = [o==l for o, l in zip(outputs, labels)]\n",
    "                accuracy += sum(acc)/len(acc)\n",
    "\n",
    "                eval_bar.update(1)\n",
    "\n",
    "            eval_bar.refresh()\n",
    "            eval_bar.reset()\n",
    "\n",
    "            accelerator.print('step : {}, accuracy  : {}'.format(global_step + 1, accuracy/len(eval_dataloader)))\n",
    "            accelerator.log({\n",
    "                \"accuracy\": accuracy/len(eval_dataloader),\n",
    "            },\n",
    "                step=global_step + 1,\n",
    "            )\n",
    "            \n",
    "        model.train()\n",
    "        global_step += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.749074074074074"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
