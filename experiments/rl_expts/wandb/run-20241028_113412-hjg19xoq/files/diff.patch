diff --git a/experiments/rl_expts/gpt2_scan_ppo.py b/experiments/rl_expts/gpt2_scan_ppo.py
index c1b1fc7..43849cb 100644
--- a/experiments/rl_expts/gpt2_scan_ppo.py
+++ b/experiments/rl_expts/gpt2_scan_ppo.py
@@ -180,19 +180,25 @@ def train(args, accelerator):
 
     # train
     global_step = 0  # tracks total steps
-    progress_bar = tqdm(range(global_step, args.train_steps), disable=not accelerator.is_main_process, position=0)
+    #progress_bar = tqdm(range(global_step, args.train_steps), disable=not accelerator.is_main_process, position=0)
     # eval bar
-    eval_bar = tqdm(range(len(eval_dataloader)), position=1)
+    #eval_bar = tqdm(range(len(eval_dataloader)), position=1)
 
     while True:
         ppo_trainer.model.train()
         # batches are left padded
         for batch in train_dataloader:
             # sample batch
+            # outputs, labels are padded per minibatch
+            # logits only for each generation step
+            # output_list[0].shape[1]-args.max_input_length == len(logit_list[0])
             output_list, label_list, logit_list = ppo_trainer.sample_batch(batch)
+            print(logit_list[0][0].shape)
+            print(logit_list[1][0].shape)
+            quit()
             # re-tokenize to right padding for forward pass
-            # generated_ids_list, attention_mask_list, gen_label_ids_list, context_label_ids_list
-            # TODO: roll logits
+            # generated_ids_list, attention_mask_list, 
+            # gen_label_ids_list, context_label_ids_list, logit_list
             rl_inputs = ppo_trainer.prepare_input_for_rl_step(
                 output_list,
                 label_list,
diff --git a/experiments/rl_expts/gpt2_scan_reinforce.ipynb b/experiments/rl_expts/gpt2_scan_reinforce.ipynb
index 2921322..000f4da 100644
--- a/experiments/rl_expts/gpt2_scan_reinforce.ipynb
+++ b/experiments/rl_expts/gpt2_scan_reinforce.ipynb
@@ -782,12 +782,86 @@
   },
   {
    "cell_type": "code",
-   "execution_count": null,
+   "execution_count": 1,
    "metadata": {},
    "outputs": [],
    "source": [
-    "0.749074074074074"
+    "import torch\n",
+    "\n",
+    "def roll_along(arr, shifts, dim):\n",
+    "    assert arr.ndim - 1 == shifts.ndim\n",
+    "    dim %= arr.ndim\n",
+    "    shape = (1,) * dim + (-1,) + (1,) * (arr.ndim - dim - 1)\n",
+    "    dim_indices = torch.arange(arr.shape[dim]).reshape(shape)\n",
+    "    indices = (dim_indices - shifts.unsqueeze(dim)) % arr.shape[dim]\n",
+    "    return torch.gather(arr, dim, indices)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 2,
+   "metadata": {},
+   "outputs": [],
+   "source": [
+    "mat = torch.tensor(\n",
+    "    [[1,2,3],\n",
+    "     [4,5,6],\n",
+    "     [7,8,9]]\n",
+    ")\n",
+    "\n",
+    "shifts = torch.tensor([0, 1, 2])"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 3,
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "tensor([[1, 8, 6],\n",
+       "        [4, 2, 9],\n",
+       "        [7, 5, 3]])"
+      ]
+     },
+     "execution_count": 3,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "roll_along(mat, shifts, dim=0)"
+   ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": 4,
+   "metadata": {},
+   "outputs": [
+    {
+     "data": {
+      "text/plain": [
+       "tensor([[1, 2, 3],\n",
+       "        [6, 4, 5],\n",
+       "        [8, 9, 7]])"
+      ]
+     },
+     "execution_count": 4,
+     "metadata": {},
+     "output_type": "execute_result"
+    }
+   ],
+   "source": [
+    "roll_along(mat, shifts, dim=1)"
    ]
+  },
+  {
+   "cell_type": "code",
+   "execution_count": null,
+   "metadata": {},
+   "outputs": [],
+   "source": []
   }
  ],
  "metadata": {
@@ -806,7 +880,7 @@
    "name": "python",
    "nbconvert_exporter": "python",
    "pygments_lexer": "ipython3",
-   "version": "3.12.7"
+   "version": "3.12.0"
   }
  },
  "nbformat": 4,
