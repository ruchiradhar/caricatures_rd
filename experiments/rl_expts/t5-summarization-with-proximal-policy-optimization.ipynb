{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Proximal Policy Optimization example for T5 text summarization model\n","### Based on [this notebook](https://github.com/sinanuozdemir/pearson-gpt-training-engineer/blob/main/notebooks/rl_flan_t5_summaries.ipynb) by [Sinan Ozdemir](https://github.com/sinanuozdemir) with minor changes"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:40:25.296330Z","iopub.status.busy":"2023-09-24T16:40:25.293321Z","iopub.status.idle":"2023-09-24T16:40:41.355765Z","shell.execute_reply":"2023-09-24T16:40:41.354763Z","shell.execute_reply.started":"2023-09-24T16:40:25.296286Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2.20.0\n"]}],"source":["# Import necessary dependencies\n","import warnings  # Import Warnings to suppress unnecessary warnings\n","\n","# Suppress warning messages\n","warnings.filterwarnings(\"ignore\")\n","\n","# Import datasets module and print its version\n","import datasets\n","print(datasets.__version__)\n","\n","# Import the load_dataset function from datasets\n","from datasets import load_dataset\n","\n","# Import other essential libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","# Import the load_dataset function from datasets (again, redundant)\n","from datasets import load_dataset\n","\n","# Import tokenizer and pipeline from transformers\n","from transformers import AutoTokenizer, pipeline\n","\n","# Import components related to reinforcement learning from TRL (Text-to-Text Reinforcement Learning) library\n","from trl import PPOTrainer, PPOConfig, create_reference_model, AutoModelForSeq2SeqLMWithValueHead\n","import torch\n","\n","# Import tqdm for progress bars\n","from tqdm.auto import tqdm\n","\n","# Import tokenizer and model for sequence classification from transformers\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification\n"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:40:41.357869Z","iopub.status.busy":"2023-09-24T16:40:41.357452Z","iopub.status.idle":"2023-09-24T16:40:41.365536Z","shell.execute_reply":"2023-09-24T16:40:41.364598Z","shell.execute_reply.started":"2023-09-24T16:40:41.357830Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["cuda\n"]}],"source":["# Create a PyTorch device object that represents the selected CUDA device(s).\n","device = torch.device(\"cuda\")\n","\n","# Print the selected CUDA device to the console.\n","print(device)"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:40:41.370921Z","iopub.status.busy":"2023-09-24T16:40:41.370145Z","iopub.status.idle":"2023-09-24T16:40:41.382121Z","shell.execute_reply":"2023-09-24T16:40:41.381245Z","shell.execute_reply.started":"2023-09-24T16:40:41.370889Z"},"trusted":true},"outputs":[],"source":["# Define parameters\n","N_EPOCHS = 5 # number of epochs for training\n","BATCH_SIZE = 16 # batch size\n","TRY_SAMPLE_DATA = False # If True, try a small sample of data to accelerate the pipeline\n","INITIAL_MODEL = \"google/flan-t5-small\" # Initial model\n","SAVED_MODEL = \"flan-t5-small-with-ppo\" # Saved model location\n","EVAL_SUMMARIES = 50 # Number of summaries produced during evaluation"]},{"cell_type":"markdown","metadata":{},"source":["# Create reward pipeline"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:40:41.384339Z","iopub.status.busy":"2023-09-24T16:40:41.383654Z","iopub.status.idle":"2023-09-24T16:40:48.165865Z","shell.execute_reply":"2023-09-24T16:40:48.164805Z","shell.execute_reply.started":"2023-09-24T16:40:41.384306Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"]}],"source":["# Create a sentiment analysis pipeline using the 'cardiffnlp/twitter-roberta-base-sentiment' model.\n","sentiment_pipeline = pipeline('text-classification', 'cardiffnlp/twitter-roberta-base-sentiment')\n","\n","# Define a function to extract neutral sentiment scores from a list of texts.\n","def get_neutral_scores(texts):\n","    scores = []  # Initialize an empty list to store the neutral sentiment scores.\n","\n","    # Perform sentiment analysis on the input texts, requesting raw logits as results.\n","    results = sentiment_pipeline(texts, function_to_apply='none', top_k=None)\n","\n","    # Iterate through the results for each input text.\n","    for result in results:\n","        # Iterate through the labels and their corresponding scores in the result.\n","        for label in result:\n","            # Check if the label corresponds to neutral sentiment ('LABEL_1').\n","            if label['label'] == 'LABEL_1':\n","                # Append the neutral sentiment score to the 'scores' list.\n","                scores.append(label['score'])\n","    \n","    # Return the list of neutral sentiment scores.\n","    return scores\n","\n","# Test the 'get_neutral_scores' function with a list of example texts.\n","neutral_scores = get_neutral_scores(['hello', 'I love you!', 'I hate you'])"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/plain":["[0.8519183397293091, -0.7468031644821167, -0.5696877837181091]"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["neutral_scores"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:40:48.167994Z","iopub.status.busy":"2023-09-24T16:40:48.167463Z","iopub.status.idle":"2023-09-24T16:40:53.674321Z","shell.execute_reply":"2023-09-24T16:40:53.673245Z","shell.execute_reply.started":"2023-09-24T16:40:48.167953Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of the model checkpoint at textattack/roberta-base-CoLA were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n","- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"]}],"source":["# Importing necessary libraries and modules\n","cola_tokenizer = AutoTokenizer.from_pretrained(\"textattack/roberta-base-CoLA\")  # Load the tokenizer for RoBERTa model\n","cola_model = AutoModelForSequenceClassification.from_pretrained(\"textattack/roberta-base-CoLA\")  # Load the pre-trained RoBERTa model\n","\n","# Creating a text classification pipeline using the loaded model and tokenizer\n","cola_pipeline = pipeline('text-classification', model=cola_model, tokenizer=cola_tokenizer)\n","\n","# Define a function to get CoLA scores for a list of input texts\n","def get_cola_scores(texts):\n","    scores = []  # Initialize an empty list to store scores\n","    \n","    # Use the pipeline to generate scores for the input texts\n","    # Set function_to_apply to 'none' to get logits, which can be negative (desired)\n","    # Set top_k to None to include all possible labels\n","    results = cola_pipeline(texts, function_to_apply='none', top_k=None)\n","    \n","    # Iterate through the results\n","    for result in results:\n","        for label in result:\n","            if label['label'] == 'LABEL_1':  # Check if the label corresponds to 'LABEL_1' (good grammar)\n","                scores.append(label['score'])  # Append the score to the scores list\n","    \n","    return scores  # Return the list of scores for 'LABEL_1'"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:40:53.676516Z","iopub.status.busy":"2023-09-24T16:40:53.676123Z","iopub.status.idle":"2023-09-24T16:40:54.050890Z","shell.execute_reply":"2023-09-24T16:40:54.049100Z","shell.execute_reply.started":"2023-09-24T16:40:53.676483Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["CoLA Scores (Linguistic Acceptability): [-0.03150612488389015]\n","Sentiment Analysis Scores (Neutral, Positive, Negative): [0.30984699726104736]\n"]}],"source":["# The following code defines a string variable 'test' that contains a news report.\n","test = \"\"\"German police arrest 29-year-old man suspected of plotting truck attack on ice rink in Berlin, \n","killing 12 people, Reuters-German police say: 'It's a shame to have been arrested,' \n","a German police spokesman said in a statement.\"\"\"\n","\n","# The 'get_cola_scores' function is used to analyze the linguistic acceptability of the text.\n","# It assesses how grammatically correct and well-structured the sentence is.\n","cola_scores = get_cola_scores([test])\n","print(\"CoLA Scores (Linguistic Acceptability):\", cola_scores)\n","\n","# The 'get_neutral_scores' function is used to evaluate the sentiment of the text.\n","# It determines whether the text has a neutral, positive, or negative sentiment.\n","neutral_scores = get_neutral_scores([test])\n","print(\"Sentiment Analysis Scores (Neutral, Positive, Negative):\", neutral_scores)"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:40:54.053352Z","iopub.status.busy":"2023-09-24T16:40:54.052335Z","iopub.status.idle":"2023-09-24T16:40:55.062413Z","shell.execute_reply":"2023-09-24T16:40:55.061101Z","shell.execute_reply.started":"2023-09-24T16:40:54.053304Z"},"trusted":true},"outputs":[{"ename":"TypeError","evalue":"PPOConfig.__init__() got an unexpected keyword argument 'log_with'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Reinforcement Learning Configuration\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Create a configuration object for the PPO (Proximal Policy Optimization) algorithm.\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[43mPPOConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreward_model_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mINITIAL_MODEL\u001b[49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Specify the name of the pre-trained model to use.\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# Set the batch size for training.\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmini_batch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2e-5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                 \u001b[49m\u001b[38;5;66;43;03m# Define the learning rate for the optimizer.\u001b[39;49;00m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremove_unused_columns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Keep unused data columns in the training dataset.\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_with\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mwandb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m                  \u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Number of gradient accumulation steps before updating the model.\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Set a random seed for reproducibility.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mseed(\u001b[38;5;241m42\u001b[39m)\n","\u001b[0;31mTypeError\u001b[0m: PPOConfig.__init__() got an unexpected keyword argument 'log_with'"]}],"source":["# Reinforcement Learning Configuration\n","\n","# Create a configuration object for the PPO (Proximal Policy Optimization) algorithm.\n","config = PPOConfig(\n","    reward_model_path=INITIAL_MODEL,           # Specify the name of the pre-trained model to use.\n","    batch_size=BATCH_SIZE,              # Set the batch size for training.\n","    mini_batch_size=4,\n","    learning_rate=2e-5,                 # Define the learning rate for the optimizer.\n","    remove_unused_columns=False,        # Keep unused data columns in the training dataset.\n","    log_with=\"wandb\",                  \n","    gradient_accumulation_steps=1,      # Number of gradient accumulation steps before updating the model.\n",")\n","\n","# Set a random seed for reproducibility.\n","np.random.seed(42)"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:40:55.072641Z","iopub.status.busy":"2023-09-24T16:40:55.068112Z","iopub.status.idle":"2023-09-24T16:41:03.339982Z","shell.execute_reply":"2023-09-24T16:41:03.338498Z","shell.execute_reply.started":"2023-09-24T16:40:55.072591Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7b142f17accc46acb799f8ad5f88a94a","version_major":2,"version_minor":0},"text/plain":["config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c6607784663b4ac69e6ef38c84e17130","version_major":2,"version_minor":0},"text/plain":["model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ddab77f1467b4dc1b0aeb4422dfa476a","version_major":2,"version_minor":0},"text/plain":["generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"66fe7b38bee04a80b1f7f37145e2a92e","version_major":2,"version_minor":0},"text/plain":["pytorch_model.bin:   0%|          | 0.00/308M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"e73d6bfbfe0748a189d2380e8bb1d6ba","version_major":2,"version_minor":0},"text/plain":["tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"39c63e70834c4be491aaabc0ffd08a59","version_major":2,"version_minor":0},"text/plain":["spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c7ccb9d9d39842b5b956403aa06bc4c6","version_major":2,"version_minor":0},"text/plain":["tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f0219bf5c438402689bd099ad60aa364","version_major":2,"version_minor":0},"text/plain":["special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Initialize a FLAN-T5 model for sequence-to-sequence tasks with a value head\n","t5_model = AutoModelForSeq2SeqLMWithValueHead.from_pretrained(\n","    config.model_name\n",")  # This model will be updated during training\n","\n","# Create a reference model based on the initial FLAN-T5 model\n","t5_model_ref = create_reference_model(t5_model)  # This reference model is never updated\n","\n","# Initialize a tokenizer for the FLAN-T5 model\n","t5_tokenizer = AutoTokenizer.from_pretrained(config.model_name)"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:41:03.345338Z","iopub.status.busy":"2023-09-24T16:41:03.344957Z","iopub.status.idle":"2023-09-24T16:41:05.951407Z","shell.execute_reply":"2023-09-24T16:41:05.950384Z","shell.execute_reply.started":"2023-09-24T16:41:03.345307Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"945c87f45d1e4a7c8ef4de04711f09d1","version_major":2,"version_minor":0},"text/plain":["Downloading readme:   0%|          | 0.00/2.02k [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"d698444fa28e4c1b9898f6e8fd09f4a3","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/1.54M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7038165fa4b9489f87112c2391bc38a7","version_major":2,"version_minor":0},"text/plain":["Downloading data:   0%|          | 0.00/31.7M [00:00<?, ?B/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"3e33af1542cc47cd8d270b292cdaefff","version_major":2,"version_minor":0},"text/plain":["Generating train split:   0%|          | 0/1000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b64982d2c6cd4ae3b85d171276add66d","version_major":2,"version_minor":0},"text/plain":["Generating test split:   0%|          | 0/20417 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# Load the \"argilla/news-summary\" dataset using the load_dataset function.\n","# This function fetches the dataset from the Hugging Face Datasets Hub.\n","dataset = load_dataset(\"argilla/news-summary\")"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:41:05.953260Z","iopub.status.busy":"2023-09-24T16:41:05.952883Z","iopub.status.idle":"2023-09-24T16:41:05.969180Z","shell.execute_reply":"2023-09-24T16:41:05.967225Z","shell.execute_reply.started":"2023-09-24T16:41:05.953225Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'prediction', 'prediction_agent', 'annotation', 'annotation_agent', 'id', 'metadata', 'status', 'event_timestamp', 'metrics'],\n","        num_rows: 1000\n","    })\n","    test: Dataset({\n","        features: ['text', 'prediction', 'prediction_agent', 'annotation', 'annotation_agent', 'id', 'metadata', 'status', 'event_timestamp', 'metrics'],\n","        num_rows: 20417\n","    })\n","})"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["dataset"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:41:05.971503Z","iopub.status.busy":"2023-09-24T16:41:05.971061Z","iopub.status.idle":"2023-09-24T16:42:04.076311Z","shell.execute_reply":"2023-09-24T16:42:04.075236Z","shell.execute_reply.started":"2023-09-24T16:41:05.971425Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b1a70783905b4efca95da1049a754f22","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stderr","output_type":"stream","text":["Token indices sequence length is longer than the specified maximum sequence length for this model (631 > 512). Running this sequence through the model will result in indexing errors\n"]},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"42ada301d6f0494a8d861be31fc745ef","version_major":2,"version_minor":0},"text/plain":["Map:   0%|          | 0/20417 [00:00<?, ? examples/s]"]},"metadata":{},"output_type":"display_data"}],"source":["# In this code, we are using the `map` function to process a dataset.\n","\n","dataset = dataset.map(\n","    # Within the `map` function, we use a lambda function to transform each element in the dataset.\n","    lambda x: {\n","        \"input_ids\": t5_tokenizer.encode('summarize: ' + x[\"text\"], return_tensors=\"pt\")\n","        # We are adding a key \"input_ids\" to the dataset element's dictionary.\n","        # The value is generated by encoding the text with the T5 tokenizer.\n","        # The \"summarize: \" prefix is added to the input text, which is a common format for summarization tasks.\n","        # The `return_tensors=\"pt\"` argument specifies that the output should be PyTorch tensors.\n","    },\n","    # The `batched` parameter is set to False, indicating that we process one element at a time.\n",")"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:42:04.079002Z","iopub.status.busy":"2023-09-24T16:42:04.078169Z","iopub.status.idle":"2023-09-24T16:42:04.093633Z","shell.execute_reply":"2023-09-24T16:42:04.092373Z","shell.execute_reply.started":"2023-09-24T16:42:04.078949Z"},"trusted":true},"outputs":[],"source":["# Remove unnecessary columns from the dataset.\n","dataset = dataset.remove_columns(['metadata', 'status', 'event_timestamp', 'metrics', 'prediction', 'prediction_agent', 'annotation'])\n","\n","# Set the dataset format to PyTorch, which is commonly used for deep learning tasks.\n","dataset.set_format(\"pytorch\")"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'annotation_agent', 'id', 'input_ids'],\n","        num_rows: 1000\n","    })\n","    test: Dataset({\n","        features: ['text', 'annotation_agent', 'id', 'input_ids'],\n","        num_rows: 20417\n","    })\n","})"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["dataset"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:42:04.096179Z","iopub.status.busy":"2023-09-24T16:42:04.095723Z","iopub.status.idle":"2023-09-24T16:42:04.161810Z","shell.execute_reply":"2023-09-24T16:42:04.160240Z","shell.execute_reply.started":"2023-09-24T16:42:04.096140Z"},"trusted":true},"outputs":[],"source":["# Define a function called 'collator' that takes a list of dictionaries as input.\n","def collator(data):\n","    # Create a dictionary comprehension to aggregate values from each dictionary.\n","    # The 'key' variable iterates through the keys of the first dictionary in 'data'.\n","    # This assumes that 'data' is not an empty list.\n","    return dict((key, [d[key] for d in data]) for key in data[0])\n","\n","# The function 'collator' takes a list of dictionaries and returns a new dictionary\n","# where keys are taken from the first dictionary in 'data', and the values are lists\n","# containing values associated with each key from all dictionaries in 'data'."]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:42:04.164011Z","iopub.status.busy":"2023-09-24T16:42:04.163519Z","iopub.status.idle":"2023-09-24T16:42:04.297231Z","shell.execute_reply":"2023-09-24T16:42:04.296140Z","shell.execute_reply.started":"2023-09-24T16:42:04.163969Z"},"trusted":true},"outputs":[],"source":["# Load our reference FLAN-T5 Model\n","\n","# Import the AutoTokenizer class from the Hugging Face Transformers library to load the tokenizer for the INITIAL_MODEL model.\n","t5_tokenizer = AutoTokenizer.from_pretrained(INITIAL_MODEL)\n","\n","# Define generation hyperparameters\n","\n","# Set the minimum length of the generated output to 64 tokens.\n","generation_kwargs = {\n","    \"min_length\": 64,\n","\n","    # Configure the number of beams for beam search. Higher values lead to more diverse but slower generation.\n","    \"num_beams\": 5,  # lookahead parameter\n","\n","    # Control the repetition of n-grams in the generated text. A value of 5 reduces repetitive phrases.\n","    \"no_repeat_ngram_size\": 5,  # presence penalty\n","\n","    # Enable sampling during generation to introduce randomness in the output.\n","    \"do_sample\": True,\n","\n","    # Specify the padding token ID to use when generating sequences.\n","    \"pad_token_id\": t5_tokenizer.pad_token_id,\n","\n","    # Set the maximum length of the generated output to 256 tokens.\n","    \"max_length\": 256,\n","\n","    # Define the end-of-sequence token ID to signal the end of the generated text.\n","    \"eos_token_id\": t5_tokenizer.eos_token_id,\n","}"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:42:04.301318Z","iopub.status.busy":"2023-09-24T16:42:04.300527Z","iopub.status.idle":"2023-09-24T16:42:04.309892Z","shell.execute_reply":"2023-09-24T16:42:04.308709Z","shell.execute_reply.started":"2023-09-24T16:42:04.301245Z"},"trusted":true},"outputs":[{"data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['text', 'annotation_agent', 'id', 'input_ids'],\n","        num_rows: 1000\n","    })\n","    test: Dataset({\n","        features: ['text', 'annotation_agent', 'id', 'input_ids'],\n","        num_rows: 20417\n","    })\n","})"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["if TRY_SAMPLE_DATA:\n","    dataset['train'] = dataset['train'].select([*range(64)])\n","dataset"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:42:04.312410Z","iopub.status.busy":"2023-09-24T16:42:04.311300Z","iopub.status.idle":"2023-09-24T16:42:09.839180Z","shell.execute_reply":"2023-09-24T16:42:09.838078Z","shell.execute_reply.started":"2023-09-24T16:42:04.312371Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msuicune\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"data":{"text/html":["wandb version 0.18.5 is available!  To upgrade, please run:\n"," $ pip install wandb --upgrade"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Tracking run with wandb version 0.17.1"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Run data is saved locally in <code>/home/drdo/Caricatures/experiments/rl_expts/wandb/run-20241024_155042-nh5bspxh</code>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":["Syncing run <strong><a href='https://wandb.ai/suicune/trl/runs/nh5bspxh' target=\"_blank\">lilac-durian-2</a></strong> to <a href='https://wandb.ai/suicune/trl' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View project at <a href='https://wandb.ai/suicune/trl' target=\"_blank\">https://wandb.ai/suicune/trl</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"data":{"text/html":[" View run at <a href='https://wandb.ai/suicune/trl/runs/nh5bspxh' target=\"_blank\">https://wandb.ai/suicune/trl/runs/nh5bspxh</a>"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"}],"source":["# Create a PPOTrainer instance for training a Proximal Policy Optimization (PPO) model.\n","ppo_trainer = PPOTrainer(\n","    config,  # Configuration settings for the trainer.\n","    t5_model,  # The primary T5 model used for training.\n","    t5_model_ref,  # A reference T5 model for comparison or other purposes.\n","    t5_tokenizer,  # Tokenizer used to process input data.\n","    dataset['train'],  # Training dataset used to train the PPO model.\n","    data_collator=collator  # Data collator for processing training data batches.\n",")\n"]},{"cell_type":"markdown","metadata":{},"source":["# Train and validate the model using PPO"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T16:42:09.841375Z","iopub.status.busy":"2023-09-24T16:42:09.840981Z","iopub.status.idle":"2023-09-24T20:35:53.456484Z","shell.execute_reply":"2023-09-24T20:35:53.455235Z","shell.execute_reply.started":"2023-09-24T16:42:09.841339Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"594000a475624e2b91519227d2dfdd30","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/5 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"1667aaaa8c0a4b198e376ee32547b29b","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/62 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["[tensor([    0,  1013,  9677,  2095,  2762, 10319, 11741,    21,  6285, 21078,\n","           18,   107,    32,     6, 13404,    13,  6627,   354,    77,  1531,\n","            6,    30,  3991,    13, 10564,    13,  2019,   826,    70, 12732,\n","          139,  1449,   161,    44,   112,   629,     6,     3,     9,  2095,\n","         2314,   243,    30,  2089,     6,     3, 18844, 16854,     3,     9,\n","            3,     7, 18461,    21,  1013,  7054,     3,     7,     3,     7,\n","        18461,    38,  2145,     5,     1], device='cuda:0'), tensor([    0, 10021, 13074,   851,    18, 10806, 20855, 10213,  1883,   160,\n","          525,   981, 12508,   607,     6,  6013,  3049,     5,  1914,  1230,\n","            6,    12,     8,   915,     6,    28,     3,     9,   580,    12,\n","         8994,  7459,  2523,    12,   143,   347,   112,  2055,  1104,  5146,\n","            5,    96,   634,  1176,   794,    21,  7459,  2523,    19,   823,\n","            3,    88,    56, 13859,    12,     8, 17875,  2348,    57,   334,\n","        13074,  4775,    16,     8,   941,     3,  1498,    11,   143,   112,\n","         1104,  5146,   347,     6,    38, 20855, 10213,    65,   612,   976,\n","         5468,     7, 15893, 26378, 27815,   243,    16,     3,     9,  2493,\n","            5,     1], device='cuda:0'), tensor([    0,  7199,   120, 18279,    16,    70, 22461,    13,  8994, 13074,\n","         4775,  7459,  2523,     6,   128,  6173,    18,  1123,   138,   189,\n","           63,   412,     5,   134,     5,  4367,   113,   577,    16, 11252,\n","         6525,    33,   615,  9203,     3, 22853,    70,  3703,     6,    12,\n","           52,    29,   344,  1025,    18,  8071,  4341,     6,   914,     3,\n","         7388,    30,   323,    18,  3849,  3171,  4233,     7,    42,   237,\n","        10601,    21,     3, 19679, 20855, 10213,     5,     1],\n","       device='cuda:0'), tensor([    0,    71,  1013, 21986,    15,     7,    15, 16054,   563, 17316,\n","           15,     7,   789, 12673,    13, 20550,    70,  1247,   163,     3,\n","            9,   239,   227,     8,  2251,  3814,     3,     9, 18682,  6608,\n","           16,     3,     9,   662,    18,  1201,   615,    24,    65,  4792,\n","            3,   324,     7,    13,  2909,    13,   151,     6,     3, 18844,\n","           18,  1649, 15727,   152,  1506,  3193,    41, 18844,    61,     3,\n","           18,  1013, 21986,     3,     7,   789,   845, 18682,  6608,    56,\n","          995, 20386,  1637,   592,    12, 14705,     7,  4682,    16,     8,\n","         6237,     5,     1], device='cuda:0'), tensor([    0,   412,     5,   134,     5,  1661,  7459,  2523,    19, 10785,\n","           53,    95,   112,   960,    21,     3,     9,   126,  5752,    21,\n","            8,   412,     5,   134,     5,  2069,  2137,     6,  1338,    28,\n","         1798,  5034,  9473, 10510,  8595, 10265,   107,    11,   386,   717,\n","           11, 12894,     3,     9,  1357,   416,   847,     5,  2523,    65,\n","         3150,  5259,     3,    88,   164, 22993,  2700, 10803,  6651,  8158,\n","           17,     3,   476,  8890,    12,     8,   442,     5,  1022, 11956,\n","        26458,     6,    80,    13,     8,   750, 13062,     7,    30,     8,\n","        10803,    22,     7,  1476,     6,    92,  1736,    28,  2523,  2283,\n","           48,   471,    81,     8, 10803,   613,     6,     8,  3556,  1887,\n","         3559,  2196,    30,  1701,     5,     1], device='cuda:0'), tensor([    0, 27796,     3,     7,   491,     3, 31589, 20026,     7,  4792,\n","           16, 12893, 17613,    30,   192, 12293,    16,  2069, 27796,     6,\n","            3,     9,   415,  2314,    11,  2797,   243,     6,  2651,    24,\n","            3,     9,   792,    13,   874,   130,  4792,    16,     8, 17613,\n","           16, 27796,     3,     7,   491, 11835,    26,     9, 13062,   342,\n","           30,  1856,     6,    46,  2314,   243,     6,  2651,    24,    80,\n","          130,  4792,   116,     3,     9, 12893,  7774,     8,   443,    79,\n","          130,  6723,    16,     5,     1], device='cuda:0'), tensor([    0,   412,     5,   134,     5,  5191,   845,  2523,    22,     7,\n","         1111,  4514,   225,   916,    16,  8854,   383,    46,  4912,  3958,\n","            7,  1614,  1132,     6,     3,     9,  5191,   243,    30,  2089,\n","            6,  1315,    12,     8,   412,     5,   134,     5,  5034,  2243,\n","           13,     3, 29641,    21,     8,  3570,    13,  8183,    41,  6463,\n","         4112,    61,    16,  2386,     6,   309,     5,   254,     5,     6,\n","            3,     9,   412,     5,   134,     5,  3570, 12330,   243,     5,\n","            1], device='cuda:0'), tensor([    0,   622,     7,   145,   997,   716,   227,  7459,  2523,   808,\n","          828,     6,   112, 27405,   708,     3, 11600, 21760,     5, 15278,\n","            7,  2924,    24,     8,  4374,    44,  2523,    22,     7, 23782,\n","           53,    18,    77,    47,  2755,   145,    44, 20653,  4534,    22,\n","            7,   166, 13074,     3, 30634,    16,  2464,  2953,     8,   166,\n","            3,    52,  4636,   302,    16,   112,  3602,     3,    18,    68,\n","           59,     8,   336,     5,  2523,    22,     7,   166,   215,    16,\n","          828,    47, 11999,    57,    46,  4962,   139,   823,   112,  2066,\n","         7632, 21135,    26,    28,     8,  4263,   789,    12,  2603,     8,\n","         4356,  6138,     6, 21548,     7,    11, 11262,    13,   615,    28,\n","         1117,  7054,     6,    11,    46,  1941,    12,  1903,   268,    18,\n","         4905,  6704,     5,  1029,     8,   456,     6,     8,  1945,  1384,\n","          808,     3,     9,  4719,   757,  1295,     6, 17316,    53,     8,\n","          783,    13,  8072,    51,    53,  7194,    13,     8,     3, 30634,\n","           16,     3,     9,   194,    24,  4283,    12,   365,  5540,     8,\n","         4374,   812,     5,  3373,  7471, 16655, 25727,    52,     3, 15585,\n","           24,     8,  1383,   130,    59,   125,    79,  3776,    11,    24,\n","         4374,     7,    13,  5441,   812,  7533,  2523,   240,     8,     3,\n","           32,     9,   189,    13,   828,     5,     1], device='cuda:0'), tensor([    0,     3,  6934,  3063, 23143,   134,    41, 18844,    61,     3,\n","           18,   290,     7,     9,   932,  2299,    93,  7290,   295,     6,\n","           28,  1659, 10631,   365,   160,  2053,     6,  3371,  5752,  4297,\n","         3966,    18, 19298, 10745,  3383,  1219,     3,  5385,     7,   227,\n","         2851,    28,     8,  2390,  3427,  6323,   336,   471,     5,    37,\n","          934,    57,     3,     9, 13077,    49, 21484,    15, 23542, 25688,\n","            3,  2544,    90, 15461,   905,    13,     3,     9, 10745,  3383,\n","           18, 15881,  2634,    16,  1186,  2953, 13423,    16,  1524,     6,\n","          243, 10745,  3383,   816,   160,  7027,    57,  3392,     7,   147,\n","        13857,    28,   160,   293, 23053,  6323,     7,    38,   255,  1380,\n","           21,  3371,   199,    12,   482,    72,   562,    21, 23264,    44,\n","          234,     5,   465,  5299,  1670,    47,   347,    45, 10745,  3383,\n","            3,     7,   828,     6,    84,    65,     3,     9,  1291,    13,\n","           59,  1670,    53,    30,  2279,    13,  4677,     5,     1],\n","       device='cuda:0'), tensor([    0, 16388,     7,    13,   239,    21,   412,     5,   134,     5,\n","         1661,  7459,  2523,    22,     7,  3602,    30,  1701,    10,  2523,\n","          223,     7,     3,     9,  1357,    57,   112,  1798,  1157,  1034,\n","        17013,     6,  2457,  8223,    29,    29,     6,    12,  2762, 26510,\n","           16, 28167, 17032,    13,   487,     3,  3010,   344,   112,  2066,\n","           11,  4623,     6,    68,   132,    19,   150,  5299,  1320,     8,\n","         1690,    56,    36,  7020,     5,    37,  2523,  3602,     3,     7,\n","           40,   265,     7,  1473,    30,     3,     9,   620,    13,  1668,\n","          807,    45,   165,  6658,  2913,   147,  4010,     9,  6726,    12,\n","         5241,   748, 16319,    11,   307, 11018,  4514,     7,    30,   412,\n","            5,   134,     5,  9177,    11,  3031,  1942,   364,     5, 14465,\n","         2762,     7,    12,   577,   323,  7012,     7,    28,     8,   907,\n","         1323,    11,   474,    30,     3,     9,  1465,   522,  2177,    13,\n","         1661,     3,     4,    23, 20500,  2462,    22,     7,   166,  1338,\n","           28,  2523,   416,   471,     5,     1], device='cuda:0'), tensor([    0,     3, 26342,     3, 19775, 16479,   134,    87,   518, 21337,\n","         2365, 16270,    41, 18844,    61,     3,    18,    37,  7021,    18,\n","         9485,   105,   371,  2632,    21, 15287,   153,  2426,  4973,    15,\n","           26,    44,  7291,    22,     7,  8206,    11,  6424,    15,    15,\n","           22,     7,  3661,    30,  2721,    16,     3,     9,  6894,    12,\n","         1190,     8, 16534,    22,   819,     6,     3,     9,  6721, 15264,\n","           13,  2559, 11458,  5386,    11,   105,  1890, 27522,   642,    45,\n","         2852,   412,     5,   134,     5,  5347, 15852,     5,     1],\n","       device='cuda:0'), tensor([    0,  1184,   965,  5004,    23,   122,   221,  4662,    19,    30,\n","          112,   194,    12, 20501,    12,   217,  9196,     6, 21768,    29,\n","          538,  6878,    49,   584,  5934,   243,    30,  2089,     5,  5004,\n","           23,   122,    26,  4662,    19,   966,  1852,  1107,    12, 20501,\n","           11,    19,   243,    12,    36,    30,   112,   194,     6,   584,\n","         5934,   243,    30,   165,   475,     5,   345,    76,    23,   122,\n","          221,  4662,    56,   942,  9196,    11,  1827,  8675,   270,     5,\n","            1], device='cuda:0'), tensor([    0,    41, 18844,    61,     3,    18,    37,   412,     5,   134,\n","            5, 10907,  5421,  8009, 10504,    22,     7,  2090,     3, 27431,\n","         2448,    16,  4442,    30,  2875,   581,     3,     9,  1207,  4843,\n","           13,  8994, 12334,   147,   762,    45,     8,  3193,    22,     7,\n","         5834,    13,     8,  1548,     7,  5186,   839,  3744, 14605,    12,\n","            8,   194,     3,    88,    65,  4828,  3030,   112,   613,     5,\n","         2276,  2741,    53,   274,     8,  1384,  5421,  1799,  3201,     6,\n","         4117, 18217,  2866,     6,   530,   576,    63,   116,  1380,   823,\n","            3,    88,   133,  1992,   112,  1657,     6,    84,  8982,    15,\n","            7,    16,  1718,  3070, 15623,    30,     8,  4492,    11,  8975,\n","           43,     3,  9951,    21,  1661,  2523,    12,  1472,   376,     6,\n","           11, 18217,  2866,    19,  5456,     3,  2781,    32,  1271,    12,\n","           36,     3,     9,   487,  6167,     3,   122, 14659,    29,  7265,\n","          138,  4775,    16,  3070,     1], device='cuda:0'), tensor([    0,  7459,  2523,   845,     3,    88,  2746,    12,   414,   797,\n","          380,    21, 16706,  8263,  1637,  6237,  6653,  3272,   491,    18,\n","        27409,    22,     7, 10030,     5,   299,    56,  2523,   916,     3,\n","            9,  2450, 29449,   380,    11,   761,   478,    21,     8, 16706,\n","        10021,  5205,     7,     6,     3,     9, 17952,    13, 16054,  1637,\n","            6,    84,    19,  1374,     3,     9,  1591, 12130,    12,     3,\n","         1162,    17, 11117,  1015,    45,     8,   690,    13,  2922,  1824,\n","         1824,     9,     6,  1784,    13,   165,  1044,    18, 28901,   212,\n","         7446,   547,    15,    58,     1], device='cuda:0'), tensor([    0,   312,  3478,    15,     7,    15,  1661,  9411,    71,    32,\n","          202,   845,   412,     5,   134,     5,  1661,  7459,  2523,    31,\n","            7, 14807,  1357,    47,  5107,    11, 16026,     8, 20327,    13,\n","            8,   907,  1323,    38,     3,     9, 11630,    13,     8,  3065,\n","          433,    16,     8,  1719,     5,   216,   243,     8,  1357,   141,\n","          474,   223,     8,  3065,   433,    57,  4160,     6,    11,   141,\n","        16026,  3518,  7606,    11,  2361,  1252,  7606,     5,     1],\n","       device='cuda:0'), tensor([    0,     3, 18844,    10,    37, 25527,    29,  1745,    13,     3,\n","           17, 18329,     7,  1669, 16146,  2617,  4646, 14840,   165,   884,\n","          313,  2673,    11,  3168,   165,  5391,   147,     8,  1851,   227,\n","          386,    13,   165,  1652,   130,  2538,    12,  1687,    16,     8,\n","         2808,   797,  2982,     5,    37,   386,  9357,     7,    11,     8,\n","         9699,    53,    13,     3,     9,  4509,  3490,  6935,    16,   662,\n","         2450,  6032,    30,  1701,     5,   100,    19,     3,     9,  4541,\n","          495,    13,     3, 10398,   127,  1575,    16,   268,   844,    16,\n","         5107,  1467,    13,     8,   684,     6,     3,     9,   349,  6978,\n","            6,   113,  1380,    59,    12,    36,  2650,   250,    13,  1455,\n","         3315,     6,  1219,     3, 18844,    30,  1771,     5,   242,     8,\n","         1455,    13,    69,  1652,     6,    62,  1500,    12, 12547,   884,\n","          313,    68,    56, 16329,  5721,    41,  9168,  1135,    61,    11,\n","        11556,  8303,  1389,  2986,     6,     8,  6978,   243,     5,     1],\n","       device='cuda:0')]\n"]},{"ename":"RuntimeError","evalue":"No active exception to reraise","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","Cell \u001b[0;32mIn[42], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m     response_tensors\u001b[38;5;241m.\u001b[39mappend(response\u001b[38;5;241m.\u001b[39msqueeze())\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(response_tensors)\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Decode the response tensors to obtain the generated text\u001b[39;00m\n\u001b[1;32m     25\u001b[0m game_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m [t5_tokenizer\u001b[38;5;241m.\u001b[39mdecode(r\u001b[38;5;241m.\u001b[39msqueeze(), skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m response_tensors]\n","\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"]}],"source":["# Loop through training epochs\n","\n","for epoch in tqdm(range(N_EPOCHS)):\n","    avg_rewards = []\n","    # Iterate through batches in the data loader\n","    for batch in tqdm(ppo_trainer.dataloader):\n","        # Create a dictionary to store game data for this batch\n","        game_data = dict()\n","\n","        # Prepend the 'summarize:' token to each text in the batch\n","        game_data[\"query\"] = ['summarize: ' + b for b in batch[\"text\"]]\n","\n","        # Generate responses from the updated t5 model\n","        input_tensors = [_.squeeze() for _ in batch[\"input_ids\"]]\n","        response_tensors = []\n","        for query in input_tensors:\n","            # Generate a response using PPO with specified generation parameters\n","            response = ppo_trainer.generate(query.squeeze(), **generation_kwargs)\n","            response_tensors.append(response.squeeze())\n","\n","        # Decode the response tensors to obtain the generated text\n","        game_data[\"response\"] = [t5_tokenizer.decode(r.squeeze(), skip_special_tokens=False) for r in response_tensors]\n","\n","        # Calculate and store clean responses (without special tokens)\n","        game_data[\"clean_response\"] = [t5_tokenizer.decode(r.squeeze(), skip_special_tokens=True) for r in response_tensors]\n","\n","        # Calculate cola_scores and neutral_scores\n","        game_data['cola_scores'] = get_cola_scores(game_data[\"clean_response\"])\n","        game_data['neutral_scores'] = get_neutral_scores(game_data[\"clean_response\"])\n","\n","        # Calculate rewards based on neutral_scores\n","        rewards = game_data['neutral_scores']\n","\n","        # Combine cola_scores and neutral_scores into a single reward score\n","        transposed_lists = zip(game_data['cola_scores'], game_data['neutral_scores'])\n","        rewards = [1 * values[0] + 0.5 * values[1] for values in transposed_lists]\n","        rewards = [torch.tensor([_]) for _ in rewards]\n","        \n","        # Calculate batch average reward before the PPO training\n","        avg_reward = np.mean([r.cpu().numpy() for r in rewards])\n","        print(f\"Average reward for the batch is {avg_reward:.4f}\")\n","        \n","        # Append batch reward to avg rewards\n","        avg_rewards.append(avg_reward)\n","\n","        # Run Proximal Policy Optimization (PPO) training\n","        stats = ppo_trainer.step(input_tensors, response_tensors, rewards)\n","\n","        # Calculate and log the mean reward for this batch\n","        stats['env/reward'] = np.mean([r.cpu().numpy() for r in rewards])\n","\n","        # Log training statistics, game data, and rewards\n","        ppo_trainer.log_stats(stats, game_data, rewards)\n","    # Print average reward at the end of each run\n","    print(f\">>>>> Average reward for epoch {epoch} is: {np.mean(avg_rewards):.4f}\" )"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-09-24T20:35:53.458984Z","iopub.status.busy":"2023-09-24T20:35:53.458523Z","iopub.status.idle":"2023-09-24T20:35:54.071659Z","shell.execute_reply":"2023-09-24T20:35:54.070335Z","shell.execute_reply.started":"2023-09-24T20:35:53.458943Z"},"trusted":true},"outputs":[{"data":{"text/plain":["('flan-t5-small-with-ppo/tokenizer_config.json',\n"," 'flan-t5-small-with-ppo/special_tokens_map.json',\n"," 'flan-t5-small-with-ppo/spiece.model',\n"," 'flan-t5-small-with-ppo/added_tokens.json',\n"," 'flan-t5-small-with-ppo/tokenizer.json')"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# Save the T5 model to the specified directory.\n","t5_model.save_pretrained(SAVED_MODEL)\n","\n","# Save the T5 tokenizer to the same directory as the model for future use.\n","t5_tokenizer.save_pretrained(SAVED_MODEL)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.0"}},"nbformat":4,"nbformat_minor":4}
