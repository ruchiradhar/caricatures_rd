{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "975b8951-366d-4add-aa11-8291ec8a1bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.1 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/by/rktr_w596p97pmt8_cbknvs80000gn/T/ipykernel_57625/76753913.py\", line 3, in <module>\n",
      "    from transformers import AutoTokenizer, GPT2LMHeadModel\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/transformers/__init__.py\", line 26, in <module>\n",
      "    from . import dependency_versions_check\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/transformers/dependency_versions_check.py\", line 16, in <module>\n",
      "    from .utils.versions import require_version, require_version_core\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/transformers/utils/__init__.py\", line 34, in <module>\n",
      "    from .generic import (\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/transformers/utils/generic.py\", line 462, in <module>\n",
      "    import torch.utils._pytree as _torch_pytree\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, GPT2LMHeadModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54539932-d248-4c9f-9085-ec4b3a633196",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ujan/opt/anaconda3/envs/transformer-test/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1614: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(\"/home/drdo/Caricatures/models/scan_dummy_tokens_gpt2/checkpoint-40000\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('openai-community/gpt2')\n",
    "\n",
    "#model = GPT2LMHeadModel.from_pretrained(\"/home/drdo/Caricatures/models/scan_dummy_tokens_gpt2/checkpoint-40000\")\n",
    "model = GPT2LMHeadModel.from_pretrained('openai-community/gpt2')\n",
    "\n",
    "model.generation_config.max_length = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c75252d",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 9\n",
    "dummy_token = \"<empty>\"\n",
    "\n",
    "# command type maps\n",
    "actions = {\n",
    "    \"walk\": \"I_WALK\",\n",
    "    \"run\": \"I_RUN\",\n",
    "    \"jump\": \"I_JUMP\",\n",
    "    \"look\": \"I_LOOK\",\n",
    "    \"turn\": dummy_token,\n",
    "    dummy_token: dummy_token,\n",
    "    }\n",
    "\n",
    "turns = {\n",
    "    \"around\": \"yyyy\",\n",
    "    \"opposite\": \"yy\",\n",
    "    dummy_token: dummy_token\n",
    "}\n",
    "\n",
    "directions = {\n",
    "    \"right\": \"I_TURN_RIGHT\",\n",
    "    \"left\": \"I_TURN_LEFT\",\n",
    "    dummy_token: dummy_token\n",
    "}\n",
    "\n",
    "nums = {\n",
    "    \"twice\": \"xx\",\n",
    "    \"thrice\": \"xxx\",\n",
    "    dummy_token: dummy_token\n",
    "}\n",
    "\n",
    "conjs = [\"and\", \"after\", dummy_token]\n",
    "\n",
    "# command structure\n",
    "command_structure = {\n",
    "    0: actions,\n",
    "    1: turns,\n",
    "    2: directions,\n",
    "    3: nums,\n",
    "    4: conjs,\n",
    "    5: actions,\n",
    "    6: turns,\n",
    "    7: directions,\n",
    "    8: nums,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf8598b0-3238-48c4-84e2-4a10926400fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"scan\", \"simple\", trust_remote_code=True)\n",
    "column_names = dataset[\"train\"].column_names\n",
    "input_column = column_names[0]\n",
    "output_column = column_names[1]\n",
    "\n",
    "def add_empty_token(x):\n",
    "    command_str = x[input_column]\n",
    "    command = command_str.split()\n",
    "    padded_command = []\n",
    "    index = 0\n",
    "    c = 0\n",
    "    while index < max_len:\n",
    "        expected_cs = command_structure[index]\n",
    "        if c < len(command) and command[c] in expected_cs:\n",
    "            padded_command.append(command[c])\n",
    "            c += 1\n",
    "        else:\n",
    "            padded_command.append(dummy_token)\n",
    "        index += 1\n",
    "    \n",
    "    x[input_column] = ' '.join(padded_command)\n",
    "    return x\n",
    "\n",
    "test_dataset = dataset[\"test\"].map(\n",
    "    add_empty_token,\n",
    "    batched=False,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01a0ec91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'commands': 'run <empty> right twice after walk <empty> right twice',\n",
       " 'actions': 'I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d8c4ba5-c140-443e-9aa9-38d98ba5b639",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "torch.Size([1, 12, 13, 64])\n",
      "torch.Size([1, 12, 13, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 14, 64])\n",
      "torch.Size([1, 12, 14, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 15, 64])\n",
      "torch.Size([1, 12, 15, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 16, 64])\n",
      "torch.Size([1, 12, 16, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 17, 64])\n",
      "torch.Size([1, 12, 17, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 18, 64])\n",
      "torch.Size([1, 12, 18, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 19, 64])\n",
      "torch.Size([1, 12, 19, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 20, 64])\n",
      "torch.Size([1, 12, 20, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 21, 64])\n",
      "torch.Size([1, 12, 21, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 22, 64])\n",
      "torch.Size([1, 12, 22, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 23, 64])\n",
      "torch.Size([1, 12, 23, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 24, 64])\n",
      "torch.Size([1, 12, 24, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 25, 64])\n",
      "torch.Size([1, 12, 25, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 26, 64])\n",
      "torch.Size([1, 12, 26, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 27, 64])\n",
      "torch.Size([1, 12, 27, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 28, 64])\n",
      "torch.Size([1, 12, 28, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 29, 64])\n",
      "torch.Size([1, 12, 29, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 30, 64])\n",
      "torch.Size([1, 12, 30, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 31, 64])\n",
      "torch.Size([1, 12, 31, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 32, 64])\n",
      "torch.Size([1, 12, 32, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 33, 64])\n",
      "torch.Size([1, 12, 33, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 34, 64])\n",
      "torch.Size([1, 12, 34, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 35, 64])\n",
      "torch.Size([1, 12, 35, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 36, 64])\n",
      "torch.Size([1, 12, 36, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 37, 64])\n",
      "torch.Size([1, 12, 37, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 38, 64])\n",
      "torch.Size([1, 12, 38, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 39, 64])\n",
      "torch.Size([1, 12, 39, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 40, 64])\n",
      "torch.Size([1, 12, 40, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 41, 64])\n",
      "torch.Size([1, 12, 41, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 42, 64])\n",
      "torch.Size([1, 12, 42, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 43, 64])\n",
      "torch.Size([1, 12, 43, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 44, 64])\n",
      "torch.Size([1, 12, 44, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 45, 64])\n",
      "torch.Size([1, 12, 45, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 46, 64])\n",
      "torch.Size([1, 12, 46, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 47, 64])\n",
      "torch.Size([1, 12, 47, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 48, 64])\n",
      "torch.Size([1, 12, 48, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 49, 64])\n",
      "torch.Size([1, 12, 49, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 50, 64])\n",
      "torch.Size([1, 12, 50, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 51, 64])\n",
      "torch.Size([1, 12, 51, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 52, 64])\n",
      "torch.Size([1, 12, 52, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 53, 64])\n",
      "torch.Size([1, 12, 53, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 54, 64])\n",
      "torch.Size([1, 12, 54, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 55, 64])\n",
      "torch.Size([1, 12, 55, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 56, 64])\n",
      "torch.Size([1, 12, 56, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 57, 64])\n",
      "torch.Size([1, 12, 57, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 58, 64])\n",
      "torch.Size([1, 12, 58, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 59, 64])\n",
      "torch.Size([1, 12, 59, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 60, 64])\n",
      "torch.Size([1, 12, 60, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 61, 64])\n",
      "torch.Size([1, 12, 61, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 62, 64])\n",
      "torch.Size([1, 12, 62, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 63, 64])\n",
      "torch.Size([1, 12, 63, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 64, 64])\n",
      "torch.Size([1, 12, 64, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 65, 64])\n",
      "torch.Size([1, 12, 65, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 66, 64])\n",
      "torch.Size([1, 12, 66, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 67, 64])\n",
      "torch.Size([1, 12, 67, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 68, 64])\n",
      "torch.Size([1, 12, 68, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 69, 64])\n",
      "torch.Size([1, 12, 69, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 70, 64])\n",
      "torch.Size([1, 12, 70, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 71, 64])\n",
      "torch.Size([1, 12, 71, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 72, 64])\n",
      "torch.Size([1, 12, 72, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 73, 64])\n",
      "torch.Size([1, 12, 73, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 74, 64])\n",
      "torch.Size([1, 12, 74, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 75, 64])\n",
      "torch.Size([1, 12, 75, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 76, 64])\n",
      "torch.Size([1, 12, 76, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 77, 64])\n",
      "torch.Size([1, 12, 77, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 78, 64])\n",
      "torch.Size([1, 12, 78, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 79, 64])\n",
      "torch.Size([1, 12, 79, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 80, 64])\n",
      "torch.Size([1, 12, 80, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 81, 64])\n",
      "torch.Size([1, 12, 81, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 82, 64])\n",
      "torch.Size([1, 12, 82, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 83, 64])\n",
      "torch.Size([1, 12, 83, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 84, 64])\n",
      "torch.Size([1, 12, 84, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 85, 64])\n",
      "torch.Size([1, 12, 85, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 86, 64])\n",
      "torch.Size([1, 12, 86, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 87, 64])\n",
      "torch.Size([1, 12, 87, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 88, 64])\n",
      "torch.Size([1, 12, 88, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 89, 64])\n",
      "torch.Size([1, 12, 89, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 90, 64])\n",
      "torch.Size([1, 12, 90, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 91, 64])\n",
      "torch.Size([1, 12, 91, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 92, 64])\n",
      "torch.Size([1, 12, 92, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 93, 64])\n",
      "torch.Size([1, 12, 93, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 94, 64])\n",
      "torch.Size([1, 12, 94, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 95, 64])\n",
      "torch.Size([1, 12, 95, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 96, 64])\n",
      "torch.Size([1, 12, 96, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 97, 64])\n",
      "torch.Size([1, 12, 97, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 98, 64])\n",
      "torch.Size([1, 12, 98, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 99, 64])\n",
      "torch.Size([1, 12, 99, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 100, 64])\n",
      "torch.Size([1, 12, 100, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 101, 64])\n",
      "torch.Size([1, 12, 101, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 102, 64])\n",
      "torch.Size([1, 12, 102, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 103, 64])\n",
      "torch.Size([1, 12, 103, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 104, 64])\n",
      "torch.Size([1, 12, 104, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 105, 64])\n",
      "torch.Size([1, 12, 105, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 106, 64])\n",
      "torch.Size([1, 12, 106, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 107, 64])\n",
      "torch.Size([1, 12, 107, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 108, 64])\n",
      "torch.Size([1, 12, 108, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 109, 64])\n",
      "torch.Size([1, 12, 109, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 110, 64])\n",
      "torch.Size([1, 12, 110, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 111, 64])\n",
      "torch.Size([1, 12, 111, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 112, 64])\n",
      "torch.Size([1, 12, 112, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 113, 64])\n",
      "torch.Size([1, 12, 113, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 114, 64])\n",
      "torch.Size([1, 12, 114, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 115, 64])\n",
      "torch.Size([1, 12, 115, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 116, 64])\n",
      "torch.Size([1, 12, 116, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 117, 64])\n",
      "torch.Size([1, 12, 117, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 118, 64])\n",
      "torch.Size([1, 12, 118, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 119, 64])\n",
      "torch.Size([1, 12, 119, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 120, 64])\n",
      "torch.Size([1, 12, 120, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 121, 64])\n",
      "torch.Size([1, 12, 121, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 122, 64])\n",
      "torch.Size([1, 12, 122, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 123, 64])\n",
      "torch.Size([1, 12, 123, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 124, 64])\n",
      "torch.Size([1, 12, 124, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 125, 64])\n",
      "torch.Size([1, 12, 125, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 126, 64])\n",
      "torch.Size([1, 12, 126, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 127, 64])\n",
      "torch.Size([1, 12, 127, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 128, 64])\n",
      "torch.Size([1, 12, 128, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 129, 64])\n",
      "torch.Size([1, 12, 129, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 130, 64])\n",
      "torch.Size([1, 12, 130, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 131, 64])\n",
      "torch.Size([1, 12, 131, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 132, 64])\n",
      "torch.Size([1, 12, 132, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 133, 64])\n",
      "torch.Size([1, 12, 133, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 134, 64])\n",
      "torch.Size([1, 12, 134, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 135, 64])\n",
      "torch.Size([1, 12, 135, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 136, 64])\n",
      "torch.Size([1, 12, 136, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 137, 64])\n",
      "torch.Size([1, 12, 137, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 138, 64])\n",
      "torch.Size([1, 12, 138, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 139, 64])\n",
      "torch.Size([1, 12, 139, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 140, 64])\n",
      "torch.Size([1, 12, 140, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 141, 64])\n",
      "torch.Size([1, 12, 141, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 142, 64])\n",
      "torch.Size([1, 12, 142, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 143, 64])\n",
      "torch.Size([1, 12, 143, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 144, 64])\n",
      "torch.Size([1, 12, 144, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 145, 64])\n",
      "torch.Size([1, 12, 145, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 146, 64])\n",
      "torch.Size([1, 12, 146, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 147, 64])\n",
      "torch.Size([1, 12, 147, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 148, 64])\n",
      "torch.Size([1, 12, 148, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 149, 64])\n",
      "torch.Size([1, 12, 149, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 150, 64])\n",
      "torch.Size([1, 12, 150, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 151, 64])\n",
      "torch.Size([1, 12, 151, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 152, 64])\n",
      "torch.Size([1, 12, 152, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 153, 64])\n",
      "torch.Size([1, 12, 153, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 154, 64])\n",
      "torch.Size([1, 12, 154, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 155, 64])\n",
      "torch.Size([1, 12, 155, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 156, 64])\n",
      "torch.Size([1, 12, 156, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 157, 64])\n",
      "torch.Size([1, 12, 157, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 158, 64])\n",
      "torch.Size([1, 12, 158, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 159, 64])\n",
      "torch.Size([1, 12, 159, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 160, 64])\n",
      "torch.Size([1, 12, 160, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 161, 64])\n",
      "torch.Size([1, 12, 161, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 162, 64])\n",
      "torch.Size([1, 12, 162, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 163, 64])\n",
      "torch.Size([1, 12, 163, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 164, 64])\n",
      "torch.Size([1, 12, 164, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 165, 64])\n",
      "torch.Size([1, 12, 165, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 166, 64])\n",
      "torch.Size([1, 12, 166, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 167, 64])\n",
      "torch.Size([1, 12, 167, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 168, 64])\n",
      "torch.Size([1, 12, 168, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 169, 64])\n",
      "torch.Size([1, 12, 169, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 170, 64])\n",
      "torch.Size([1, 12, 170, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 171, 64])\n",
      "torch.Size([1, 12, 171, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 172, 64])\n",
      "torch.Size([1, 12, 172, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 173, 64])\n",
      "torch.Size([1, 12, 173, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 174, 64])\n",
      "torch.Size([1, 12, 174, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 175, 64])\n",
      "torch.Size([1, 12, 175, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 176, 64])\n",
      "torch.Size([1, 12, 176, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 177, 64])\n",
      "torch.Size([1, 12, 177, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 178, 64])\n",
      "torch.Size([1, 12, 178, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 179, 64])\n",
      "torch.Size([1, 12, 179, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 180, 64])\n",
      "torch.Size([1, 12, 180, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 181, 64])\n",
      "torch.Size([1, 12, 181, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 182, 64])\n",
      "torch.Size([1, 12, 182, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 183, 64])\n",
      "torch.Size([1, 12, 183, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 184, 64])\n",
      "torch.Size([1, 12, 184, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 185, 64])\n",
      "torch.Size([1, 12, 185, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 186, 64])\n",
      "torch.Size([1, 12, 186, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 187, 64])\n",
      "torch.Size([1, 12, 187, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 188, 64])\n",
      "torch.Size([1, 12, 188, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 189, 64])\n",
      "torch.Size([1, 12, 189, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 190, 64])\n",
      "torch.Size([1, 12, 190, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 191, 64])\n",
      "torch.Size([1, 12, 191, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 192, 64])\n",
      "torch.Size([1, 12, 192, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 193, 64])\n",
      "torch.Size([1, 12, 193, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 194, 64])\n",
      "torch.Size([1, 12, 194, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 195, 64])\n",
      "torch.Size([1, 12, 195, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 196, 64])\n",
      "torch.Size([1, 12, 196, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 197, 64])\n",
      "torch.Size([1, 12, 197, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 198, 64])\n",
      "torch.Size([1, 12, 198, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 199, 64])\n",
      "torch.Size([1, 12, 199, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 200, 64])\n",
      "torch.Size([1, 12, 200, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 201, 64])\n",
      "torch.Size([1, 12, 201, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 202, 64])\n",
      "torch.Size([1, 12, 202, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 203, 64])\n",
      "torch.Size([1, 12, 203, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 204, 64])\n",
      "torch.Size([1, 12, 204, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 205, 64])\n",
      "torch.Size([1, 12, 205, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 206, 64])\n",
      "torch.Size([1, 12, 206, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 207, 64])\n",
      "torch.Size([1, 12, 207, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 208, 64])\n",
      "torch.Size([1, 12, 208, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 209, 64])\n",
      "torch.Size([1, 12, 209, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 210, 64])\n",
      "torch.Size([1, 12, 210, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 211, 64])\n",
      "torch.Size([1, 12, 211, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 212, 64])\n",
      "torch.Size([1, 12, 212, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 213, 64])\n",
      "torch.Size([1, 12, 213, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 214, 64])\n",
      "torch.Size([1, 12, 214, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 215, 64])\n",
      "torch.Size([1, 12, 215, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 216, 64])\n",
      "torch.Size([1, 12, 216, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 217, 64])\n",
      "torch.Size([1, 12, 217, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 218, 64])\n",
      "torch.Size([1, 12, 218, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 219, 64])\n",
      "torch.Size([1, 12, 219, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 220, 64])\n",
      "torch.Size([1, 12, 220, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 221, 64])\n",
      "torch.Size([1, 12, 221, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 222, 64])\n",
      "torch.Size([1, 12, 222, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 223, 64])\n",
      "torch.Size([1, 12, 223, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 224, 64])\n",
      "torch.Size([1, 12, 224, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 225, 64])\n",
      "torch.Size([1, 12, 225, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 226, 64])\n",
      "torch.Size([1, 12, 226, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 227, 64])\n",
      "torch.Size([1, 12, 227, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 228, 64])\n",
      "torch.Size([1, 12, 228, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 229, 64])\n",
      "torch.Size([1, 12, 229, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 230, 64])\n",
      "torch.Size([1, 12, 230, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 231, 64])\n",
      "torch.Size([1, 12, 231, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 232, 64])\n",
      "torch.Size([1, 12, 232, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 233, 64])\n",
      "torch.Size([1, 12, 233, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 234, 64])\n",
      "torch.Size([1, 12, 234, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 235, 64])\n",
      "torch.Size([1, 12, 235, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 236, 64])\n",
      "torch.Size([1, 12, 236, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 237, 64])\n",
      "torch.Size([1, 12, 237, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 238, 64])\n",
      "torch.Size([1, 12, 238, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 239, 64])\n",
      "torch.Size([1, 12, 239, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 240, 64])\n",
      "torch.Size([1, 12, 240, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 241, 64])\n",
      "torch.Size([1, 12, 241, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 242, 64])\n",
      "torch.Size([1, 12, 242, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 243, 64])\n",
      "torch.Size([1, 12, 243, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 244, 64])\n",
      "torch.Size([1, 12, 244, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 245, 64])\n",
      "torch.Size([1, 12, 245, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 246, 64])\n",
      "torch.Size([1, 12, 246, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 247, 64])\n",
      "torch.Size([1, 12, 247, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 248, 64])\n",
      "torch.Size([1, 12, 248, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 249, 64])\n",
      "torch.Size([1, 12, 249, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 250, 64])\n",
      "torch.Size([1, 12, 250, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 251, 64])\n",
      "torch.Size([1, 12, 251, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 252, 64])\n",
      "torch.Size([1, 12, 252, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 253, 64])\n",
      "torch.Size([1, 12, 253, 64])\n",
      "\n",
      "12\n",
      "torch.Size([1, 12, 254, 64])\n",
      "torch.Size([1, 12, 254, 64])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generation_mode = GenerationMode.GREEDY_SEARCH\n",
    "\n",
    "context = 'run <empty> right twice after walk <empty> right twice'\n",
    "#inputs = tokenizer(context+tokenizer.sep_token, return_tensors=\"pt\")\n",
    "inputs = tokenizer(context, return_tensors=\"pt\")\n",
    "\n",
    "output = model.generate(**inputs)[0]\n",
    "#print(output)\n",
    "#print(tokenizer.decode(output, skip_special_tokens=False))\n",
    "\n",
    "#tokenizer.decode(output[0], skip_special_tokens=False).replace(context+tokenizer.sep_token, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b2414ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"openai-community/gpt2\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 12,\n",
       "  \"n_positions\": 1024,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.45.0.dev0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50257\n",
       "}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc0955fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "768/12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "49eb2758",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'run <empty> right twice after walk <empty> right twice<sep>I_TURN_RIGHT I_WALK I_TURN_RIGHT I_WALK I_TURN_RIGHT I_RUN I_TURN_RIGHT I_RUN<|endoftext|>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = 'run <empty> right twice after walk <empty> right twice'\n",
    "inputs = tokenizer(context, return_tensors=\"pt\")\n",
    "tokenizer.decode(model.generate(**inputs)[0], skip_special_tokens=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db52e35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = test_dataset.select(range(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d77f4f82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e19a6d27f164429be9eb6dab1f6dbfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "model.to(\"cuda\")\n",
    "bar = tqdm(range(len(testset)))\n",
    "for example in testset:\n",
    "    command = example['commands']\n",
    "    label = example['actions']\n",
    "    inputs = tokenizer(command+tokenizer.sep_token, return_tensors=\"pt\").to(\"cuda\")\n",
    "    output = model.generate(**inputs)[0].to(\"cpu\")\n",
    "    output = tokenizer.decode(output, skip_special_tokens=False).replace(command+tokenizer.sep_token, '')\n",
    "    output = output.replace(tokenizer.eos_token, '')\n",
    "    if output == label:\n",
    "        count += 1\n",
    "    bar.update(1)\n",
    "\n",
    "print(count/len(testset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af6ed29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# distilgpt2 : acc = 0.6406025824964132\n",
    "# distilgpt2 : acc = 0.67 -> beam search (beam size = 3)\n",
    "# gpt2 : acc = 0.810856049736968, 0.88, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
